{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a590b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2385e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lob_model(latent_dim, T):\n",
    "\tlob_state = keras.layers.Input(shape=(T, 40, 1))\n",
    "\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (1, 2), strides=(1, 2))(lob_state)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (1, 5), strides=(1, 5))(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (1, 4))(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\tconv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "\tconv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "\t# build the inception module\n",
    "\tconvsecond_1 = keras.layers.Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "\tconvsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\tconvsecond_1 = keras.layers.Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "\tconvsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\n",
    "\tconvsecond_2 = keras.layers.Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "\tconvsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\tconvsecond_2 = keras.layers.Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "\tconvsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\n",
    "\tconvsecond_3 = keras.layers.MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "\tconvsecond_3 = keras.layers.Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "\tconvsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "\n",
    "\tconvsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "\tconv_reshape = keras.layers.Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(\n",
    "\t\tconvsecond_output)\n",
    "\n",
    "\tattn_input = conv_reshape\n",
    "\tattn_input_last = attn_input[:, -1:, :]\n",
    "\n",
    "\tmulti_head_attn_layer_1 = keras.layers.MultiHeadAttention(num_heads=10, key_dim=16, output_shape=64)\n",
    "\n",
    "\tattn_output, weight = multi_head_attn_layer_1(attn_input_last, attn_input, return_attention_scores=True)\n",
    "\n",
    "\tattn_output = keras.layers.Flatten()(attn_output)\n",
    "\n",
    "\t# add Batch Normalization\n",
    "\t# attn_output = keras.layers.BatchNormalization()(attn_output)\n",
    "\n",
    "\t# add Layer Normalization\n",
    "\t# attn_output = keras.layers.LayerNormalization()(attn_output)\n",
    "\n",
    "\treturn keras.models.Model(lob_state, attn_output)\n",
    "\n",
    "def getLabel(mid_price, horizon, threshold=1e-5):\n",
    "    price_past = mid_price.rolling(window=horizon).mean()\n",
    "\n",
    "    price_future = mid_price.copy()\n",
    "    price_future[:-horizon] = price_past[horizon:]\n",
    "    price_future[-horizon:] = np.nan\n",
    "\n",
    "    pct_change = (price_future - price_past)/price_past\n",
    "    pct_change[pct_change>=threshold] = 1\n",
    "    pct_change[(pct_change<threshold) & (-threshold<pct_change)] = 2\n",
    "    pct_change[pct_change<=-threshold] = 3\n",
    "    return pct_change\n",
    "\n",
    "def process_data(data):\n",
    "    #data = data[(data.time > '10:00:00')&(data.time < '14:30:00')]\n",
    "    data = data.dropna()\n",
    "    data.y = getLabel(data.midprice, 10)\n",
    "\n",
    "    for i in range(10):\n",
    "        data[f'ask_price_{i+1}'] = data[f'ask_price_{i+1}']/data['midprice'] - 1\n",
    "        data[f'bid_price_{i+1}'] = data[f'bid_price_{i+1}']/data['midprice'] - 1\n",
    "        data[f'ask_quantity_{i+1}'] = data[f'ask_quantity_{i+1}']/data[f'ask_quantity_{i+1}'].max()\n",
    "        data[f'bid_quantity_{i+1}'] = data[f'bid_quantity_{i+1}']/data[f'bid_quantity_{i+1}'].max()\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "    return data.set_index(['timestamp'])\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "\t[N, D] = X.shape\n",
    "\tdf = np.array(X)\n",
    "\tdY = np.array(Y)\n",
    "\tdataY = to_categorical(dY[T-1:N], 3)\n",
    "\tdataX = np.zeros((N-T+1, T, D))\n",
    "\tfor i in range(T, N+1):\n",
    "\t\tdataX[i-T] = df[i-T:i, :]\n",
    "\treturn dataX.reshape(dataX.shape+(1,)), dataY\n",
    "\n",
    "def prepare_data(file_path):\n",
    "\tdf = pd.read_csv(file_path)\n",
    "\tdf['midprice'] = 0.5 * (df['ask_price_1'] + df['bid_price_1'])\n",
    "\tdf = df.dropna()\n",
    "\n",
    "\tdf['y'] = getLabel(df.midprice, 10)\n",
    "\tdf['y'] = df['y'] - 1\n",
    "\n",
    "\tfor i in range(10):\n",
    "\t\tdf[f'ask_price_{i+1}'] = df[f'ask_price_{i+1}'] / df['midprice'] - 1\n",
    "\t\tdf[f'bid_price_{i+1}'] = df[f'bid_price_{i+1}'] / df['midprice'] - 1\n",
    "\t\tdf[f'ask_quantity_{i + 1}'] = df[f'ask_quantity_{i + 1}'] / df[f'ask_quantity_{i + 1}'].max()\n",
    "\t\tdf[f'bid_quantity_{i + 1}'] = df[f'bid_quantity_{i + 1}'] / df[f'bid_quantity_{i + 1}'].max()\n",
    "\tdf.set_index('timestamp', inplace=True)\n",
    "\n",
    "\tall_columns = []\n",
    "\tfor index in range(1,11):\n",
    "\t\tall_columns.append(f\"ask_quantity_{index}\")\n",
    "\t\tall_columns.append(f\"ask_price_{index}\")\n",
    "\t\tall_columns.append(f\"bid_quantity_{index}\")\n",
    "\t\tall_columns.append(f\"bid_price_{index}\")\n",
    "\tall_columns.append('y')\n",
    "\tdf = df[all_columns]\n",
    "\tdf = df.dropna()\n",
    "\treturn np.array(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab3d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = prepare_data(r'data/600519/20230320/order_book.csv')\n",
    "df_val = prepare_data(r'data/600519/20230321/order_book.csv')\n",
    "df_test = prepare_data(r'data/600519/20230322/order_book.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1103a19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48595, 50, 40, 1) (48595, 3)\n",
      "(75751, 50, 40, 1) (75751, 3)\n",
      "(43013, 50, 40, 1) (43013, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T=50\n",
    "trainX, trainY = data_classification(df_train[:-10,:-1], df_train[:-10, -1:], T)\n",
    "valX, valY = data_classification(df_val[:-10,:-1], df_val[:-10, -1:], T)\n",
    "testX, testY = data_classification(df_test[:-10,:-1], df_test[:-10, -1:], T)\n",
    "\n",
    "print(trainX.shape, trainY.shape)\n",
    "print(valX.shape, valY.shape)\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4a6a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 50, 40, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 50, 20, 32)   96          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 50, 20, 32)   0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 50, 20, 32)   4128        ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 50, 20, 32)   0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 50, 20, 32)   4128        ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 50, 20, 32)   0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 50, 4, 32)    5152        ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 50, 4, 32)    0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 50, 4, 32)    4128        ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 50, 4, 32)    0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 50, 4, 32)    4128        ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 50, 4, 32)    0           ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 50, 1, 32)    4128        ['leaky_re_lu_19[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 50, 1, 32)    0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 50, 1, 32)    4128        ['leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 50, 1, 32)    0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 50, 1, 32)    4128        ['leaky_re_lu_21[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)     (None, 50, 1, 32)    0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 50, 1, 64)    2112        ['leaky_re_lu_22[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 50, 1, 64)    2112        ['leaky_re_lu_22[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 50, 1, 32)   0           ['leaky_re_lu_22[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 50, 1, 64)    12352       ['leaky_re_lu_23[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 50, 1, 64)    20544       ['leaky_re_lu_25[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 50, 1, 64)    2112        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_27 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 50, 1, 192)   0           ['leaky_re_lu_24[0][0]',         \n",
      "                                                                  'leaky_re_lu_26[0][0]',         \n",
      "                                                                  'leaky_re_lu_27[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 50, 192)      0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 1, 192)      0           ['reshape_1[0][0]']              \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  ((None, 1, 64),     102944      ['tf.__operators__.getitem_1[0][0\n",
      " eadAttention)                   (None, 10, 1, 50))              ]',                              \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 64)           0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 176,320\n",
      "Trainable params: 176,320\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_3 (InputLayer)        [(None, 50, 40, 1)]       0         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 64)                176320    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,515\n",
      "Trainable params: 176,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "checkpoint_filepath = 'model_tensorflow2/weights_china'\n",
    "\n",
    "lob_model = get_lob_model(64, T)\n",
    "lob_model.summary()\n",
    "\n",
    "def get_pretrain_model(model, T):\n",
    "    lob_state = keras.layers.Input(shape=(T, 40, 1))\n",
    "    embedding = model(lob_state)\n",
    "    output = keras.layers.Dense(3, activation='softmax')(embedding)\n",
    "\n",
    "    return keras.models.Model(lob_state, output)\n",
    "\n",
    "china_model = get_pretrain_model(lob_model, T)\n",
    "china_model.summary()\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "\tfilepath = checkpoint_filepath,\n",
    "\tsave_weights_only = True,\n",
    "\tmonitor = 'val_loss',\n",
    "\tmode = 'auto',\n",
    "\tsave_best_only = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d65c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_2/model_1/conv2d_14/Conv2D' defined at (most recent call last):\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-12-9d2c4af3e796>\", line 4, in <module>\n      china_model.fit(trainX, trainY, validation_data=(valX, valY), epochs=3, batch_size=64, verbose=2, callbacks=[model_checkpoint_callback])\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_2/model_1/conv2d_14/Conv2D'\nDNN library is not found.\n\t [[{{node model_2/model_1/conv2d_14/Conv2D}}]] [Op:__inference_train_function_4967]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m adam \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      2\u001b[0m china_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mchina_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m china_model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_tensorflow2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchina_model.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/ENTER/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_2/model_1/conv2d_14/Conv2D' defined at (most recent call last):\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-12-9d2c4af3e796>\", line 4, in <module>\n      china_model.fit(trainX, trainY, validation_data=(valX, valY), epochs=3, batch_size=64, verbose=2, callbacks=[model_checkpoint_callback])\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/userhome/31/h3590920/ENTER/envs/py39/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_2/model_1/conv2d_14/Conv2D'\nDNN library is not found.\n\t [[{{node model_2/model_1/conv2d_14/Conv2D}}]] [Op:__inference_train_function_4967]"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "china_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "china_model.fit(trainX, trainY, validation_data=(valX, valY), epochs=3, batch_size=64, verbose=2, callbacks=[model_checkpoint_callback])\n",
    "china_model.save_weights(r\"model_tensorflow2\\china_model.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a44ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
